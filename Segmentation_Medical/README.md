# Medical Image Segmentation - Comprehensive Project

## ğŸ“‹ Overview

Comprehensive project demonstrating **medical image segmentation** using two state-of-the-art approaches:

1. **U-Net 3D** - Deep learning architecture for volumetric segmentation (BraTS 2023)
2. **MedSam** - Segment Anything Model adapted for medical imaging with text prompts

## ğŸ¯ Project Goals

- Master deep learning architectures for medical image analysis
- Implement both traditional CNN approaches (U-Net) and foundation models (SAM)
- Handle volumetric 3D medical data (CT/MRI)
- Achieve high performance on medical segmentation tasks

---

## ğŸ“š Part 1: U-Net 3D Segmentation

### Architecture Overview
```
Input Volume (128Â³ voxels)
    â†“
Encoder: 4 downsampling blocks (Conv3D + BatchNorm + ReLU + MaxPool)
    â†“
Bottleneck: Dense feature extraction
    â†“
Decoder: 4 upsampling blocks (ConvTranspose3D + skip connections)
    â†“
Output: Probability map (segmentation mask)
```

### Key Concepts
- **Encoder-Decoder Pattern**: Feature extraction â†’ compression â†’ reconstruction
- **Skip Connections**: Preserve spatial information across scales
- **3D Convolutions**: Process entire volumes simultaneously
- **Batch Normalization**: Stabilize training for high-dimensional data

### Technologies
- PyTorch with `segmentation-models-pytorch-3d`
- Custom DataLoaders for efficient 3D data handling
- TensorBoard for experiment tracking

### Metrics
- Dice Score (overlap metric)
- Sensitivity/Specificity (clinical metrics)
- Hausdorff Distance (boundary accuracy)

---

## ğŸ“š Part 2: MedSam - Segment Anything for Medical Imaging

### Foundation Model Approach
```
Medical Image + Text Prompt
    â†“
Vision Transformer (ViT) Encoder
    â†“
Prompt Processing (text embedding)
    â†“
Decoder with mask generation
    â†“
High-quality segmentation mask
```

### Key Concepts
- **Vision Transformers (ViT)**: Self-attention for image understanding
- **Transfer Learning**: Leverage pre-trained SAM model
- **Interactive Segmentation**: Use text prompts for anatomical structures
- **Prompt Engineering**: Design effective prompts for medical imaging

### Technologies
- Segment Anything Model (Meta)
- MONAI for medical image utilities
- Custom text-to-mask pipeline

### Advantages
- Minimal fine-tuning required
- Flexible prompt-based approach
- Generalization across anatomies

---

## ğŸ—‚ï¸ Project Structure

```
Segmentation_Medical/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Dependencies
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_unet_3d_segmentation.ipynb    # U-Net implementation & training
â”‚   â”œâ”€â”€ 02_medsam_segmentation.ipynb     # MedSam with text prompts
â”‚   â””â”€â”€ 03_comparison_evaluation.ipynb   # Comparative analysis
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py                 # 3D dataset loading
â”‚   â”œâ”€â”€ preprocessing.py               # MRI/CT preprocessing
â”‚   â”œâ”€â”€ metrics.py                     # Medical segmentation metrics
â”‚   â”œâ”€â”€ visualization.py               # 3D volume visualization
â”‚   â””â”€â”€ augmentation.py                # Data augmentation strategies
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unet_3d.py                     # U-Net 3D implementation
â”‚   â””â”€â”€ medsam_wrapper.py              # MedSam interface
â””â”€â”€ data/                              # Data directory (BraTS 2023)
    â”œâ”€â”€ train/
    â”œâ”€â”€ val/
    â””â”€â”€ test/
```

---

## ğŸ”§ Installation & Setup

### 1. Clone Repository
```bash
git clone https://github.com/Bore237/deep-learning-certification-projects.git
cd Segmentation_Medical
```

### 2. Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Download Data
- BraTS 2023 dataset (medical imaging benchmark)
- Place in `data/` directory
- Preprocess using `utils/preprocessing.py`

---

## ğŸš€ Quick Start

### Train U-Net 3D
```python
from notebooks.unet_3d_segmentation import train_unet

# Load preprocessed data
train_loader, val_loader = get_dataloaders('data/train', 'data/val')

# Initialize model
model = UNet3D(in_channels=4, out_channels=1)

# Train
train_unet(model, train_loader, val_loader, epochs=50)
```

### Use MedSam for Inference
```python
from utils.medsam_wrapper import MedSamSegmenter

# Initialize with pre-trained weights
segmenter = MedSamSegmenter(model_path='medsam_vit_b.pth')

# Infer with text prompt
mask = segmenter.predict(image_volume, prompt="brain tumor")

# Visualize
visualize_3d_segmentation(image_volume, mask)
```

---

## ğŸ“Š Methodology Comparison

| Aspect | U-Net 3D | MedSam |
|--------|----------|--------|
| **Training Data Needed** | Large datasets | Minimal fine-tuning |
| **Architecture** | CNNs (encoder-decoder) | Vision Transformers |
| **Flexibility** | Task-specific | Multi-task capable |
| **Inference Speed** | Fast | Moderate |
| **Customization** | Full control | Limited prompt options |

---

## ğŸ’¡ Key Learning Outcomes

### Deep Learning Fundamentals
âœ… CNN architecture design (convolutions, pooling, normalization)  
âœ… Encoder-decoder patterns for dense predictions  
âœ… Loss function design for segmentation tasks  
âœ… Training strategies (optimization, scheduling, early stopping)

### 3D Medical Imaging
âœ… Volumetric data handling (128Â³ voxels, memory optimization)  
âœ… Preprocessing pipelines (normalization, resampling)  
âœ… Data augmentation for limited datasets  
âœ… Medical image formats (NIFTI, DICOM)

### Advanced Techniques
âœ… Transfer learning from foundation models  
âœ… Prompt engineering for interactive segmentation  
âœ… Ensemble methods for improved robustness  
âœ… Multi-task learning approaches

### Evaluation & Metrics
âœ… Medical-specific metrics (Dice, Sensitivity, Specificity)  
âœ… Statistical significance testing  
âœ… Cross-validation strategies  
âœ… Error analysis & visualization

---

## ğŸ“ˆ Expected Performance

- **U-Net 3D**: Dice Score > 0.85 on validation set
- **MedSam**: Qualitative results on diverse anatomies
- **Combined Ensemble**: Improved robustness and generalization

---

## ğŸ”— References

- U-Net: Ronneberger et al. (2015) - "U-Net: Convolutional Networks for Biomedical Image Segmentation"
- Segment Anything: Kirillov et al. (2023) - "Segment Anything"
- BraTS Dataset: https://www.med.upenn.edu/cbica/brats2023/

---

## ğŸ“ Notes

- All notebooks are self-contained with detailed comments
- Code follows PyTorch best practices
- Reproducible results with fixed random seeds
- GPU acceleration recommended for 3D training

---

**Author**: Deep Learning Certification Projects  
**Date**: December 2025  
**Status**: Active development
